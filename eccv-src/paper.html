<!-- htmlcs-disable  -->
<!DOCTYPE html>
<!--[if lt IE 9]><html class="ie"><![endif]-->
<html lang="en">
<head>
    <link rel="import" href="/common/meta.html?__inline">
    <link rel="import" href="/common/css.html?__inline">

    <link rel="stylesheet" type="text/css" media="screen and (min-width: 750px)" href="/css/paper/index.css">
    <link rel="stylesheet" type="text/css" media="screen and (max-width: 750px)" href="/css/paper/m-index.css">
</head>

<body>
    <link rel="import" href="/common/header.html?__inline">

    <section class="main-wrapper">
        <div class="main">
            <div class="left-content-wrapper">

                <div class="left-content-item">
                    <div class="title">
                        Important Dates
                        <!-- <img src="/public/img/common/stripe.png" class="stripe"> -->
                    </div>
                    <div class="content">
                        <p>
                            · Paper submission deadline: 22th August 2018
                        </p>
                        <p>
                            · Notification to authors: 27th August 2018
                        </p>
                        <p>
                            · Camera ready deadline: 5th September 2018
                        </p>
                    </div>
                </div>

                <div class="left-content-item">
                    <div class="title">
                        Submission Procedure
                        <!-- <img src="/public/img/common/stripe.png" class="stripe"> -->
                    </div>
                    <div class="content">
                        
                
                         <p style="color:#000">
                            we solicit submissions in the following areas:
                        </p>
                        <p>
                             ·  Autonomous navigation and exploration
                        </p>
                        <p>
                             ·  Vision-based advanced driver assistance systems
                        </p>
                        <p>
                             ·  Vision-based underwater and unmanned aerial vehicles
                        </p>
                        <p>
                             ·  Visual driver monitoring and driver-vehicle interfaces
                        </p>
                        <p>
                             ·  On-board camera calibration
                        </p>
                        <p>
                             ·  Performance evaluation of vehicular applications
                        </p>
                        <p>
                             ·  Machine learning techniques for vehicle technology
                        </p>
                        <p>
                             ·  Vision based geo-localization
                        </p>
                        <p>
                            We will have additional one or two panel session for discussion potential issues and future directions for autonomous driving.
                        </p>
                        <br>
                        </br>
                        <p style="color:#000">
                            Authors should take into account the following: 
                        </p>
                        <p>
                            The submission site is
                            <a href="https://cmt3.research.microsoft.com/User/Login?ReturnUrl=%2FVNAD2018">
                                https://cmt3.research.microsoft.com/VNAD2018
                            </a>
                        </p>
                        <p>
                             Example submission paper with detailed instructions: <a href="https://eccv2018.org/wp-content/uploads/2018/02/eccv2018submission.pdf">eccv2018submission.pdf</a>
                            </p>
                        <p>
                            LaTeX Templates (zip): <a href="https://eccv2018.org/wp-content/uploads/2018/02/eccv2018kit.zip">eccv2018kit.zip</a>
                        </p>
                        <p>
                            A complete paper should be submitted using the above templates, which are blind-submission review-formatted templates. Papers
                        </p>
                        <p>
                            with more than 14 pages (excluding references) will be rejected without review.
                        </p>
                        <p>
                            Manuscript templates can be found at the main conference website:
                            <a href="https://eccv2018.org/papersubmission/author-guidelines/">
                                https://eccv2018.org/papersubmission/author-guidelines/
                            </a>
                        </p>
                        <br/>  
                    </div>
                    <div class="submission-btn-group">
                        <a class="submission-btn" href="https://eccv2018.org/papersubmission/author-guidelines/">
                            Format
                        </a>
                        <a class="submission-btn" href="https://cmt3.research.microsoft.com/VNAD2018">
                            Submission
                        </a>
                    </div>
                </div>

                <div class="left-content-item" style="display: none;">
                    <div class="title">
                        <!-- Invited Talks -->
                        Papers
                        <!-- <img src="/public/img/common/stripe.png" class="stripe"> -->
                    </div>
                    <!-- <div class="content">
                        <div class="paper-list">
                            <div class="paper-item">
                                <img src="/public/img/common/stripe.png" width="120" height="164">
                                <div class="paper-content">
                                    <div class="title">
                                        ApolloScape - Paper
                                    </div>
                                    <div class="date">
                                        2018-03-04 In CVPR Workshop
                                    </div>

                                    <div class="text">
                                        In this dataset, Baidu provides more than 1470 full variety shows with their playback links and files containing extracted features. The time stamps of wonderful clips are labeled accurately for each video. The researchers can design algorithms and train models using these videos and labeled clips in the training dataset. The evaluation of models or algorithms is done…
                                    </div>
                                </div>
                            </div>

                            <div class="paper-item">
                                <img src="/public/img/common/stripe.png" width="120" height="164">
                                <div class="paper-content">
                                    <div class="title">
                                        ApolloScape - Paper
                                    </div>
                                    <div class="date">
                                        2018-03-04 In CVPR Workshop
                                    </div>

                                    <div class="text">
                                        In this dataset, Baidu provides more than 1470 full variety shows with their playback links and files containing extracted features. The time stamps of wonderful clips are labeled accurately for each video. The researchers can design algorithms and train models using these videos and labeled clips in the training dataset. The evaluation of models or algorithms is done…
                                    </div>
                                </div>
                            </div>

                            <div class="paper-item">
                                <img src="/public/img/common/stripe.png" width="120" height="164">
                                <div class="paper-content">
                                    <div class="title">
                                        ApolloScape - Paper
                                    </div>
                                    <div class="date">
                                        2018-03-04 In CVPR Workshop
                                    </div>

                                    <div class="text">
                                        In this dataset, Baidu provides more than 1470 full variety shows with their playback links and files containing extracted features. The time stamps of wonderful clips are labeled accurately for each video. The researchers can design algorithms and train models using these videos and labeled clips in the training dataset. The evaluation of models or algorithms is done…
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div> -->
                </div>

            </div>
            <link rel="import" href="./common/right-menu.html?__inline">
        </div>
    </section>

    <link rel="import" href="/common/footer.html?__inline">
</body>
</html>