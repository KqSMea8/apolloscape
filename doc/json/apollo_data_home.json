{"en":{"text0":"Apollo Data Open Platform","text1_1":"It opens Apollo data resources, breaks the closed-loop between the data production, ","text1_2":"sharing and the cloud data applications, provides developers with complete autonomous driving data solutions","text1_3":" to accelerate the efficiency of the innovative iteration.","text2":"Simulation Scenarios Data","text3":"Annotation Data","text4":"Demonstration Data","text5":"Related Products And Services","text6":"Upload My Data","text7":"Simulation Scenarios Data","text8":"Simulation platform","text9":"The simulation scenarios  data includes the human-edited scenarios,  covering a variety of road types, obstacle types and road environments. At the same time, it opens the cloud simulation platform to support the concurrent online verification of algorithm modules in multiple scenes to accelerate the algorithm iteration speed.","text10":"Human-edited scene set","text11":"This scenarios set comes from virtual editing, constructing a variety of scenes collected such as traffic lights and straight lanes. The rich virtual editing scenes help quickly verify the algorithm’s basic ability and accelerate the iterative efficiency.","text12":"Use now","text13":"scenarios data","text14":"Real-collected scene set","text15":"This scene set comes from real road collection, covering a variety of scenes such as traffic lights and straight lanes on urban roads, which can effectively verify the algorithm’s processing ability in complicated real scenes, and accelerate the iterative efficiency.","text16":"Use now","text17":"Scene data","text18":"Annotation Data","text19":"Training platform","text20":"Annotation data is generated by human annotation to meet deep learning and training needs. At present, we have opened up many kinds of annotation data and provide corresponding computing capabilities in the cloud for developers to train algorithms in the cloud and improve the algorithm iteration efficiency.","text_lidar_obstacle_label_title":"Laser Point Cloud Obstacle Detection And Classification","text_lidar_obstacle_label_intro":"It provides 3D point cloud annotation data, marking four types of obstacles: pedestrians, motor vehicles, non-motor vehicles and miscellaneous. The data can be used for the research, development and evaluation of obstacle detection and classification.","text23":"Use online","text24":"Sample data","text25":"121MB","text_traffic_light_label_title":"Traffic Light Detection","text_traffic_light_label_intro":"It provides common vertical traffic light image data. The data is collected in the daytime, whether it is sunny, cloudy or foggy. The data resolution is 1080P.","text28":"Use online","text29":"Sample data","text30":"88.1 MB","text_road_hackers_title":"Road Hackers","text_road_hackers_intro":"This dataset has two main types of data, which are the street view images and the vehicle movement status. The street view image provides the image in front of the vehicle. The vehicle movement status data includes the current speed of the vehicle and the trajectory curvature.","text_in_application":"In application","text34":"Sample data","text35":"6.6GB","text_2d_obstacle_label_title":"Image-Based Obstacle Detection And Classification","text_2d_obstacle_label_intro":"The data collection covers urban roads and high-speed scenes. Four major types of obstacles are humanly annotated: motor vehicles, non-motor vehicles, pedestrians and static obstacles, which can be used for the research and evaluation of the visual obstacle detection and recognition algorithms.","text_use_online":"Use online","text39":"Sample data","text40":"108MB","text_prediction_label_title":"Obstacle Trajectory Prediction","text_prediction_label_intro":"The sample data comes from the comprehensive abstract features of multi-source sensors. Each group of data provides related information of 62-dimensional vehicle and roads, which can be used in the research, development and evaluation of the obstacle behavior prediction algorithms.","text43":"Use online","text44":"Sample data","text45":"27KB","text_apollo_scape_label_title":"Scene Analysis","text_apollo_scape_label_intro":"The data includes thousands of frames of high-resolution RGB videos and the corresponding pixel-by-pixel semantic annotations. At the same time, it provides dense point clouds with semantic segmentation measurements, emergency stereoscopic videos and stereo panoramic images.","text_apply_to_use":"Apply to use","text49":"Sample data","text50":"109.7GB","text51":"Demonstration Data","text52":"Visit Apollo source code","text53":"At present, we have opened up many kinds of demo data covering sensor collection, self-positioning, end to end and other module data, helping developers debug each module code to ensure that Apollo’s latest open code module can run successfully in the developer's local environment. The capabilities of each module can be experienced through demo data.","text_sensor_title":"Vehicle System Demo Data","text_sensor_intro":"It provides the sensor data collected at real scenes (the output of each on-board module such as Lidar point cloud data, vehicle remote control data), which can be used to debug main modules in Apollo vehicles.","text56":"Download data","text57":"8.9GB","text_source_code":"source code","text_calibrator_title":"Calibrate Demo Data","text_calibrator_intro":"It provides the calibration service demo data generated by the vehicle calibration data collection tools. The data includes HDL-64ES3 raw data for about 3 minutes, combined inertial relative motion information, and corresponding md5 checksum file.","text61":"Download samples","text62":"560MB","text_visit_calibration":"calibration platform","text_e2e_title":"End-To-End Data","text_e2e_intro":"It provides input raw sensor data and output decision control instructions. The original data of the current Apollo input sensor are mainly images and the output control instructions include the steering wheel angle, acceleration and braking.","text66":"Download samples","text67":"156GB","text68":"View module source code","text_localization_title":"Self-Positioning Module Demo Data","text_localization_intro":"It provides relative trajectory, continuous video frame and deep neural network model. Developers can learn self-positioning module functions from this data set.","text71":"Download samples","text72":"237MB","text73":"View module source code","text74":"Related Products And Services","text75":"In addition to the open data, it is also equipped with open cloud services, including related products and services, data annotation platform, training learning platforms, simulation platform and calibration platform, providing Apollo developers with a complete data solution to accelerate the iterative innovation.","text76":"Data Annotation Platform","text77":"Professional Annotation team，Guranteed for the quality for the data ","text78":"Apollo Simulation Platform","text79":"A comprehensive solution for the development of autonomous vehicles","text80":"Apollo Calibration Platform","text81":"Providing professional calibration service based on vehicle end data","text82":"Apollo Training Platform","text83":"Carrying large cloud computing power for data computing","text84":"Apollo Declaration: Open Capability - Shared Resources -  Accelerated Innovation - Sustained Mutual Benefit","text85":"Upload My Data","text86":"Download data","text_multisensor_title":"Multi-Sensor Fusion Localization Data","text_multisensor_intro":"The dataset contains sensor data for a normal urban road scenario with a duration of 3 minutes and a total length of 3 km, and other basic data that  multi-sensor fusion localization module requires. The data can be used for multi-sensor fusion localization module debugging.","text_know_more":"Know more"},"zh":{"text0":"Apollo数据开放平台","text1_1":"开放Apollo数据资源，打通数据生产、共享和云端数据应用闭环，面向开发者提供完整的自动驾驶数据解决方案，","text1_2":"加速创新迭代效率。","text1_3":"","text2":"仿真场景数据","text3":"标注数据","text4":"演示数据","text5":"相关产品与服务","text6":"上传我的数据","text7":"仿真场景数据","text8":"仿真平台","text9":"仿真场景数据包括人工编辑以及真实采集的场景，覆盖多种路型、障碍物类型以及道路环境，同时开放云端仿真平台，支持算法模块在多场景中并发在线验证，加速算法迭代速度。","text10":"自动驾驶虚拟场景","text11":"本场景集来自于人工编辑，构造了红绿灯十字路口、直行车道等多种场景集合，丰富的人工编辑场景，有助于快速验证算法的基础能力，加速迭代效率。","text12":"立即使用","text13":"场景数据","text14":"实际道路真实场景","text15":"本场景集来自于真实道路采集，覆盖了城市道路中红绿灯十字路口、直行车道等多种场景，可高效验证算法在复杂真实场景中的处理能力，加速迭代效率。","text16":"立即使用","text17":"场景数据","text18":"标注数据","text19":"训练平台","text20":"标注数据是为满足深度学习训练需求，经人工标注而生成的数据，目前我们开放了多种标注数据，同时在云端配套提供相应的计算能力，供开发者在云端训练算法，提升算法迭代效率。","text_lidar_obstacle_label_title":"激光点云障碍物检测分类","text_lidar_obstacle_label_intro":"提供三维点云标注数据，标注四类障碍物：行人、机动车、非机动车及其他，可用于障碍物检测和分类算法的研发和评测。","text23":"在线使用","text24":"样例数据","text25":"121MB","text_traffic_light_label_title":"红绿灯检测","text_traffic_light_label_intro":"提供了常见竖式红绿灯的图像数据。采集时段为白天，采集天气覆盖晴天、阴天和雾天，分辨率为1080P。","text28":"在线使用","text29":"样例数据","text30":"88.1MB","text_road_hackers_title":"Road Hackers","text_road_hackers_intro":"本数据集有两种主要类型数据，街景图像和车辆运动状态。街景图像提供车前图像，车辆运动状态数据则包括车辆的当前速度和轨迹曲率。","text_in_application":"申请中","text34":"样例数据","text35":"6.6GB","text_2d_obstacle_label_title":"基于图像的障碍物检测分类","text_2d_obstacle_label_intro":"数据采集涵盖城市道路和高速场景，由人工标注出四大类障碍物：机动车、非机动车、行人及静态障碍物，可用于视觉障碍物检测识别算法的研发和评测。","text_use_online":"在线使用","text39":"样例数据","text40":"108MB","text_prediction_label_title":"障碍物轨迹预测","text_prediction_label_intro":"采样数据来源于多源传感器的综合抽象特征，每组数据提供62维车辆和道路相关信息，可用于障碍物行为预测算法的研发和评测。","text43":"在线使用","text44":"样例数据","text45":"27KB","text_apollo_scape_label_title":"场景解析","text_apollo_scape_label_intro":"数据包括了上万帧的高分辨率RGB视频和与其对应的逐像素语义标注，同时，提供了具有语义分割测量级别的稠密点云、紧急情况的立体视频以及立体全景图像。","text_apply_to_use":"申请使用","text49":"样例数据","text50":"109.7GB","text51":"演示数据","text52":"访问Apollo源码","text53":"目前我们开放了多种演示数据，覆盖了车载系统演示数据、自定位、端到端数据等模块数据，旨在帮助开发者调试各模块代码，确保Apollo最新开放的代码模块能够在开发者本地环境运行成功，通过演示数据体验各模块的能力。","text_sensor_title":"车载系统演示数据","text_sensor_intro":"提供真实场景下采集的传感器数据（激光雷达点云数据、车辆线控数据等各车载模块的输出），可以用于调试Apollo车上主要模块。","text56":"下载数据","text57":"8.9GB","text_source_code":"查看模块源码","text_calibrator_title":"标定演示数据","text_calibrator_intro":"提供车端标定数据采集工具生成的标定服务演示数据。数据包括一段约3分钟的HDL-64ES3的原始数据、组合惯导的相对运动信息，以及对应的md5校验和文件。","text61":"下载样本","text62":"560MB","text_visit_calibration":"访问标定平台","text_e2e_title":"端到端数据","text_e2e_intro":"提供输入的传感器原始数据和输出的决策控制指令。本期Apollo输入传感器的原始数据以图像为主， 输出的控制决策指令如方向盘角度、加速、刹车。","text66":"下载样本","text67":"156GB","text68":"查看模块源码","text_localization_title":"自定位模块演示数据","text_localization_intro":"提供相对轨迹、连续视频帧、深度神经网络模型。开发者可以通过本数据集了解自定位模块功能。","text71":"下载样本","text72":"237MB","text73":"查看模块源码","text74":"相关产品与服务","text75":"除开放数据外，还配套开放云端服务，包括数据标注平台，训练学习平台以及仿真平台和标定平台，为Apollo开发者提供一整套数据解决方案，加速迭代创新。","text76":"数据标注平台","text77":"专业标注团队，为数据质量护航。","text78":"Apollo 仿真平台","text79":"提供贯穿自动驾驶研发迭代过程的完整解决方案。","text80":"Apollo 标定平台","text81":"提供基于车端数据的专业标定服务。","text82":"Apollo 训练平台","text83":"搭载大规模云端计算能力，为数据运算赋能。","text84":"Apollo宣言：开放能力 共享资源 加速创新 持续共赢","text85":"上传我的数据","text86":"下载数据","text_multisensor_title":"多传感器融合定位数据","text_multisensor_intro":"本数据集提供了时长为3分钟，总里程为3km的正常城市道路场景下的传感器数据，以及多传感器融合定位模块依赖的其它基础性数据，可用于多传感器融合定位模块的调试","text_know_more":"了解更多"}}